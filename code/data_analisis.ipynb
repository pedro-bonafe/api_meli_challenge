{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721ed62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID             Full Name\n",
      "0   1         María Sánchez\n",
      "1   2          Marta Alonso\n",
      "2   3       Javier González\n",
      "3   4    Carmen López López\n",
      "4   5  Isabel Moreno Moreno\n",
      "(5000, 2)\n",
      "Nombres únicos: 3016\n",
      "count    5000.000000\n",
      "mean       17.314000\n",
      "std         4.644967\n",
      "min         8.000000\n",
      "25%        13.000000\n",
      "50%        17.000000\n",
      "75%        21.000000\n",
      "max        33.000000\n",
      "Name: Full Name, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"names_dataset.csv\")\n",
    "\n",
    "# Estructura\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "\n",
    "# Unicidad\n",
    "print(\"Nombres únicos:\", df['Full Name'].nunique())\n",
    "\n",
    "# Longitud de strings\n",
    "print(df['Full Name'].str.len().describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140fcb88",
   "metadata": {},
   "source": [
    "El dataset provisto (names_dataset.csv) contiene:\n",
    "\n",
    "* 5.000 registros\n",
    "\n",
    "* 2 columnas: ID y Full Name\n",
    "\n",
    "* Nombres completos en español, con:\n",
    "\n",
    "* Acentos\n",
    "\n",
    "* Nombres y apellidos compuestos\n",
    "\n",
    "* Cantidad variable de tokens\n",
    "\n",
    "* Ausencia de estructura explícita (nombre / apellido)\n",
    "\n",
    "Por lo tanto, el problema corresponde a matching textual, no a análisis semántico.\n",
    "\n",
    "En primer lugar comprobamos si es conveniente realizar una separación previa de los datos en nombre y apellido dado que comunmente los sistemas de información tienen esta estructura. Además la ponderación mayor al apellido podría ayudar a enfocar más el algoritmo, sin embargo dado que no hay una estructura confiable (el dataset no viene separado previamente ni con un separador) separar nombre y apellido genera un peor score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68e3ef9",
   "metadata": {},
   "source": [
    "# Alternativas evaluadas\n",
    "## A. Comparación sobre el nombre completo\n",
    "\n",
    "Este enfoque consiste en trabajar directamente sobre el nombre completo tal como aparece en el dataset. Previamente, los textos se normalizan (conversión a minúsculas y eliminación de acentos) para evitar diferencias superficiales.\n",
    "La comparación se realiza sobre el string completo utilizando técnicas de similaridad basadas en tokens y distancia de edición, lo que permite capturar variaciones de orden, errores de tipeo y omisiones parciales sin asumir una estructura fija del nombre.\n",
    "\n",
    "## B. Separación heurística de nombre y apellido\n",
    "\n",
    "En esta alternativa se intenta dividir automáticamente el nombre completo en dos partes: nombre y apellido, asumiendo que el último token corresponde al apellido y el resto al nombre.\n",
    "Luego, se calcula la similitud de cada componente por separado y se obtiene un score final ponderado, asignando mayor peso al apellido. Este enfoque busca priorizar coincidencias de apellido, aunque depende fuertemente de una heurística que no siempre se cumple en nombres reales.\n",
    "\n",
    "# Experimento empírico\n",
    "\n",
    "Se realizaron pruebas con consultas realistas contra el dataset, comparando los resultados obtenidos con ambos enfoques. El objetivo fue evaluar no solo el score numérico, sino también la calidad del ranking y la coherencia de las coincidencias devueltas.\n",
    "\n",
    "# Resultados observados\n",
    "\n",
    "El enfoque basado en el nombre completo mostró resultados más precisos y consistentes en la mayoría de los casos.\n",
    "Por el contrario, la separación heurística introdujo varios problemas: aumentó la cantidad de falsos positivos, sobreponderó coincidencias parciales de apellido y perdió información relevante en nombres compuestos. En múltiples escenarios, esto provocó que el resultado correcto quedara peor posicionado en el ranking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e59fbc",
   "metadata": {},
   "source": [
    "| Query             | Mejor match (Full) | Score    | Mejor match (Split)      | Score    |\n",
    "| ----------------- | ------------------ | -------- | ------------------------ | -------- |\n",
    "| Maria Sanchez     | María Sánchez      | 100      | María Sánchez            | 100      |\n",
    "| Juan Carlos Perez | Juan Pérez         | 100      | Juan Pérez               | 100      |\n",
    "| Luis Gonzalez     | Luis González      | 100      | **Luis Martín González** | 100      |\n",
    "| Ana Lopez         | Ana Sánchez López  | 100      | **Ana Jiménez López**    | 100      |\n",
    "| Pedro Ramirez     | Pedro Ruiz         | **78.2** | Pedro Álvarez            | **74.3** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a29344f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rapidfuzz in c:\\users\\pbonafe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.14.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\pbonafe\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ed20671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv(\"names_dataset.csv\")\n",
    "\n",
    "def normalize(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    text = \"\".join(c for c in text if not unicodedata.combining(c))\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "df[\"normalized_name\"] = df[\"Full Name\"].apply(normalize)\n",
    "\n",
    "#enfoque A\n",
    "def similarity_full(query: str, candidate: str) -> float:\n",
    "    return fuzz.token_set_ratio(query, candidate)\n",
    "\n",
    "#enfoque B\n",
    "def split_name(full_name: str):\n",
    "    tokens = full_name.split()\n",
    "    if len(tokens) == 1:\n",
    "        return tokens[0], \"\"\n",
    "    return \" \".join(tokens[:-1]), tokens[-1]\n",
    "\n",
    "def similarity_split(query: str, candidate: str, w_name=0.4, w_surname=0.6) -> float:\n",
    "    q_name, q_surname = split_name(query)\n",
    "    c_name, c_surname = split_name(candidate)\n",
    "\n",
    "    score_name = fuzz.token_set_ratio(q_name, c_name) if q_name and c_name else 0\n",
    "    score_surname = fuzz.token_set_ratio(q_surname, c_surname) if q_surname and c_surname else 0\n",
    "\n",
    "    return score_name * w_name + score_surname * w_surname\n",
    "\n",
    "\n",
    "#prueba con datos sintéticos\n",
    "queries = [\n",
    "    \"Maria Sanchez\",\n",
    "    \"Juan Carlos Perez\",\n",
    "    \"Luis Gonzalez\",\n",
    "    \"Ana Lopez\",\n",
    "    \"Pedro Ramirez\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for q in queries:\n",
    "    q_norm = normalize(q)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        full_score = similarity_full(q_norm, row[\"normalized_name\"])\n",
    "        split_score = similarity_split(q_norm, row[\"normalized_name\"])\n",
    "\n",
    "        results.append({\n",
    "            \"query\": q,\n",
    "            \"id\": row[\"ID\"],\n",
    "            \"candidate\": row[\"Full Name\"],\n",
    "            \"full_score\": round(full_score, 2),\n",
    "            \"split_score\": round(split_score, 2)\n",
    "        })\n",
    "\n",
    "#Tabla comparativa final\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d04e7cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>candidate_full</th>\n",
       "      <th>full_score</th>\n",
       "      <th>candidate_split</th>\n",
       "      <th>split_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ana Lopez</td>\n",
       "      <td>Ana López López</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Ana López López</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Juan Carlos Perez</td>\n",
       "      <td>Carlos Pérez</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Carlos Pérez</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luis Gonzalez</td>\n",
       "      <td>Dr. Luis González</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Dr. Luis González</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maria Sanchez</td>\n",
       "      <td>María Sánchez</td>\n",
       "      <td>100.00</td>\n",
       "      <td>María Sánchez</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pedro Ramirez</td>\n",
       "      <td>Pedro Ruiz</td>\n",
       "      <td>78.26</td>\n",
       "      <td>Pedro Romero Álvarez</td>\n",
       "      <td>74.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               query     candidate_full  full_score       candidate_split  \\\n",
       "0          Ana Lopez    Ana López López      100.00       Ana López López   \n",
       "1  Juan Carlos Perez       Carlos Pérez      100.00          Carlos Pérez   \n",
       "2      Luis Gonzalez  Dr. Luis González      100.00     Dr. Luis González   \n",
       "3      Maria Sanchez      María Sánchez      100.00         María Sánchez   \n",
       "4      Pedro Ramirez         Pedro Ruiz       78.26  Pedro Romero Álvarez   \n",
       "\n",
       "   split_score  \n",
       "0       100.00  \n",
       "1       100.00  \n",
       "2       100.00  \n",
       "3       100.00  \n",
       "4        74.29  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "required_cols = {\"query\", \"candidate\", \"full_score\", \"split_score\"}\n",
    "missing = required_cols - set(results_df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"results_df no tiene las columnas requeridas: {sorted(missing)}\")\n",
    "\n",
    "# 1) Mejor match por enfoque FULL (máximo full_score por query; desempate estable)\n",
    "best_full = (\n",
    "    results_df\n",
    "    .sort_values([\"query\", \"full_score\", \"id\"], ascending=[True, False, True], kind=\"mergesort\")\n",
    "    .drop_duplicates(subset=[\"query\"], keep=\"first\")\n",
    "    .rename(columns={\"candidate\": \"candidate_full\", \"full_score\": \"full_score\"})\n",
    "    .loc[:, [\"query\", \"candidate_full\", \"full_score\"]]\n",
    ")\n",
    "\n",
    "# 2) Mejor match por enfoque SPLIT (máximo split_score por query; desempate estable)\n",
    "best_split = (\n",
    "    results_df\n",
    "    .sort_values([\"query\", \"split_score\", \"id\"], ascending=[True, False, True], kind=\"mergesort\")\n",
    "    .drop_duplicates(subset=[\"query\"], keep=\"first\")\n",
    "    .rename(columns={\"candidate\": \"candidate_split\", \"split_score\": \"split_score\"})\n",
    "    .loc[:, [\"query\", \"candidate_split\", \"split_score\"]]\n",
    ")\n",
    "\n",
    "# 3) Tabla comparativa final (lado a lado)\n",
    "comparison = best_full.merge(best_split, on=\"query\", how=\"inner\")\n",
    "\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ac4385",
   "metadata": {},
   "source": [
    "# Conclusión\n",
    "\n",
    "Separar nombre y apellido sin contar con una estructura confiable en los datos introduce heurísticas frágiles que terminan degradando la precisión del matching.\n",
    "En este dataset en particular, no existe una garantía semántica de que el último token represente correctamente el apellido ni de que los tokens restantes correspondan al nombre. Asumir esa estructura genera errores sistemáticos difíciles de corregir.\n",
    "\n",
    "El enfoque más robusto, explicable y defendible consiste en trabajar sobre el nombre completo, aplicando tokenización y técnicas de comparación textual tolerantes a errores, sin forzar divisiones artificiales.\n",
    "\n",
    "# Estrategia final adoptada\n",
    "\n",
    "La estrategia elegida evita la creación de campos artificiales de nombre y apellido y se basa en la normalización del texto y el uso de métricas de similaridad que combinan comparación por tokens y distancia de edición.\n",
    "Los resultados se filtran según un umbral configurable y se ordenan de mayor a menor similitud.\n",
    "\n",
    "Este enfoque reduce falsos positivos, no depende de reglas arbitrarias, es fácil de explicar en una entrevista técnica y escala adecuadamente para el tamaño del dataset analizado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
